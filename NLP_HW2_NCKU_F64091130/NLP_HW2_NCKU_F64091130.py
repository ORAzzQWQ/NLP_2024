# -*- coding: utf-8 -*-
"""NLP_HW2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e0MK6xb_XWKC7Inocly-UF2r3kyBssMg
"""

import numpy as np
import pandas as pd
import torch
import torch.nn
import torch.nn.utils.rnn
import torch.utils.data
from torch.nn.utils.rnn import pad_sequence
import matplotlib.pyplot as plt
import seaborn as sns
import re
import random

!gdown --id 1cMuL3hF9jefka9RyF4gEBIGGeFGZYHE- -O arithmetic_NLP.zip
!unzip arithmetic_NLP.zip

df_train = pd.read_csv('arithmetic_train.csv')
df_eval = pd.read_csv('arithmetic_eval.csv')
df_train.head()

# Transform the output data to string
df_train['tgt'] = df_train['tgt'].apply(lambda x: str(x))
df_train['src'] = df_train['src'].add(df_train['tgt'])
df_train['len'] = df_train['src'].apply(lambda x: len(x))

df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))
df_eval['src'] = df_eval['src'].add(df_eval['tgt'])
df_eval['len'] = df_eval['src'].apply(lambda x: len(x))

char_to_id = {}
id_to_char = {}

characters = ['<pad>', '<eos>', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-', '*', '(', ')', '=']
for idx, char in enumerate(characters):
    char_to_id[char] = idx
    id_to_char[idx] = char

vocab_size = len(char_to_id)

print('vocab_size: {}'.format(vocab_size))

def char_id(expr, token_map):
    tokens = re.findall(r'\d|[+\-*/=()]', expr)
    id_list = [token_map[token] for token in tokens if token in token_map]
    id_list.append(token_map['<eos>'])
    return id_list

def label_id(char_id_list, token_map):
    equal_pos = char_id_list.index(token_map['='])
    return [0] * (equal_pos+1) + char_id_list[equal_pos + 1:]

df_train['char_id_list'] = df_train['src'].apply(lambda x: char_id(x, char_to_id))
df_train['label_id_list'] = df_train['char_id_list'].apply(label_id, token_map=char_to_id)  # 等號後的
df_train = df_train[['src', 'tgt', 'len', 'char_id_list', 'label_id_list']]

df_eval['char_id_list'] = df_eval['src'].apply(lambda x: char_id(x, char_to_id))
df_eval['label_id_list'] = df_eval['char_id_list'].apply(label_id, token_map=char_to_id)
df_eval = df_eval[['src', 'tgt', 'len', 'char_id_list', 'label_id_list']]

df_train.head()
# df_train.to_csv('df_train.csv', index=False)
# df_eval.to_csv('df_eval.csv', index=False)

# Model (ASK Claude and TA example)
class Dataset(torch.utils.data.Dataset):
    def __init__(self, sequences):
        self.sequences = sequences

    def __len__(self):
        # return how much data is here in the Dataset object
        return len(self.sequences)

    def __getitem__(self, index):
        # Extract the input data x and the ground truth y from the data
        data = self.sequences.iloc[index]
        x = torch.tensor(data['char_id_list'])
        y = torch.tensor(data['label_id_list'])
        return x, y

# Model Implementation
class CharRNN(torch.nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim):
        super(CharRNN, self).__init__()  # 修正：加上括號

        # Embedding layer
        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,
                                          embedding_dim=embed_dim,
                                          padding_idx=char_to_id['<pad>'])

        # Two LSTM layers
        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim,
                                       hidden_size=hidden_dim,
                                       batch_first=True)

        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim,
                                       hidden_size=hidden_dim,
                                       batch_first=True)

        # Sequential layer with linear transformations and ReLU
        self.linear = torch.nn.Sequential(
            torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim),
            torch.nn.ReLU(),
            torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size)
        )

    def forward(self, x, target=None):
        # x shape: (batch_size, sequence_length)
        batch_size = x.size(0)
        sequence_length = x.size(1)

        # 1. 嵌入層處理所有輸入
        embedded = self.embedding(x)
        # embedded shape: (batch_size, sequence_length, embed_dim)

        # 2. 通過 LSTM 層
        output1, _ = self.rnn_layer1(embedded)
        output2, _ = self.rnn_layer2(output1)
        # output2 shape: (batch_size, sequence_length, hidden_dim)

        # 3. 通過線性層得到預測
        outputs = self.linear(output2)
        # outputs shape: (batch_size, sequence_length, vocab_size)

        return outputs

    def generator(self, start_char, max_len=200):
        # Convert input characters to IDs
        char_list = [char_to_id[c] for c in start_char]

        next_char = None

        while len(char_list) < max_len:
            # Pack the char_list to tensor
            x = torch.tensor(char_list).unsqueeze(0).to(next(self.parameters()).device)

            # Input the tensor through the model layers
            embedded = self.embedding(x)
            output1, _ = self.rnn_layer1(embedded)
            output2, _ = self.rnn_layer2(output1)
            y = self.linear(output2)

            # Obtain the next token prediction
            y = y[:, -1, :]  # Get the last prediction

            # Use argmax function to get the next token prediction
            next_char = torch.argmax(y, dim=-1).item()

            if next_char == char_to_id['<eos>']:
                break

            char_list.append(next_char)

        # Convert IDs back to characters
        return [id_to_char[ch_id] for ch_id in char_list]

# (ASK Claude and ChatGPT)
def collate_fn(batch):
    # 把序列和標籤分開
    sequences, labels = zip(*batch)

    # 使用 pad_sequence 自動處理填充
    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=char_to_id['<pad>'])
    padded_labels = pad_sequence(labels, batch_first=True, padding_value=char_to_id['<pad>'])

    return padded_sequences, padded_labels

def train_step(model, optimizer, criterion, x, y):
    # 1. 獲取模型預測
    logits = model(x)

    # 2. 計算損失（注意：y需要錯一位，因為我們在預測下一個字符）
    loss = criterion(
        logits[:, :-1].reshape(-1, logits.size(-1)),  # 除去最後一個預測
        y[:, 1:].reshape(-1)  # 除去第一個目標
    )

    # 3. 反向傳播和優化
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    return loss.item()

# 使用示例

# (ASK Claude and ChatGPT)
model = CharRNN(vocab_size=len(char_to_id), embed_dim=64, hidden_dim=128)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = torch.nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)

num_epochs = 10
train_dataset = Dataset(df_train)
train_loader = torch.utils.data.DataLoader(
    train_dataset,
    batch_size=16,  # 減小 batch_size
    shuffle=True,
    collate_fn=collate_fn
)

# 訓練循環
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    batch_count = 0

    try:
        for batch_idx, (x, y) in enumerate(train_loader):
            loss = train_step(model, optimizer, criterion, x, y)
            total_loss += loss
            batch_count += 1

            if (batch_idx + 1) % 1000 == 0:
                avg_loss = total_loss / batch_count
                print(f"Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {loss:.4f}, Avg Loss: {avg_loss:.4f}")

        # 每個 epoch 結束後更新學習率
        epoch_loss = total_loss / batch_count
        scheduler.step(epoch_loss)
        print(f"Epoch {epoch+1} completed, Average Loss: {epoch_loss:.4f}")

    except Exception as e:
        print(f"Error in epoch {epoch+1}: {str(e)}")
        continue

# 保存模型
torch.save(model.state_dict(), 'char_rnn_model.pth')

# # 加载模型
# model.load_state_dict(torch.load('char_rnn_model.pth'))
# model.eval()

# (ASK Claude and ChatGPT)
def evaluate_model(model, eval_loader, device, char_to_id, id_to_char):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    criterion = torch.nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])

    # 用于存储每个字符的准确率统计
    char_stats = {char: {'correct': 0, 'total': 0} for char in char_to_id.keys()}

    with torch.no_grad():
        for batch_idx, (input_seq, target_seq) in enumerate(eval_loader):
            input_seq = input_seq.to(device)
            target_seq = target_seq.to(device)

            # 获取模型输出
            output = model(input_seq)

            # 计算损失
            loss = criterion(
                output[:, :-1].reshape(-1, len(char_to_id)),  # 除去最后一个预测
                target_seq[:, 1:].reshape(-1)  # 除去第一个目标
            )
            total_loss += loss.item()

            # 获取预测
            _, predicted = torch.max(output[:, :-1].reshape(-1, len(char_to_id)), dim=1)
            targets = target_seq[:, 1:].reshape(-1)

            # 只考虑非填充字符的预测
            mask = targets != char_to_id['<pad>']
            predicted = predicted[mask]
            targets = targets[mask]

            # 统计每个字符的准确率
            for pred, targ in zip(predicted, targets):
                pred_char = id_to_char[pred.item()]
                targ_char = id_to_char[targ.item()]

                char_stats[targ_char]['total'] += 1
                if pred_char == targ_char:
                    char_stats[targ_char]['correct'] += 1
                    correct += 1
                total += 1

    accuracy = (correct / total * 100) if total > 0 else 0
    avg_loss = total_loss / len(eval_loader)

    char_accuracies = {}
    for char, stats in char_stats.items():
        if stats['total'] > 0:
            char_accuracies[char] = (stats['correct'] / stats['total'] * 100)

    return {
        'accuracy': accuracy,
        'loss': avg_loss,
        'char_accuracies': char_accuracies
    }


def main():

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = CharRNN(vocab_size=len(char_to_id), embed_dim=64, hidden_dim=128)
    model.load_state_dict(torch.load('char_rnn_model_v3', map_location=device))
    model.to(device)
    model.eval()

    eval_dataset = Dataset(df_eval)
    eval_loader = torch.utils.data.DataLoader(
        eval_dataset,
        batch_size=16,
        shuffle=False,
        collate_fn=collate_fn
    )

    results = evaluate_model(model, eval_loader, device, char_to_id, id_to_char)

    print(f"\nEvaluation Results:")
    print(f"Overall Accuracy: {results['accuracy']:.2f}%")
    print(f"Average Loss: {results['loss']:.4f}")
    print("\nPer-character Accuracy:")

    sorted_chars = sorted(
        results['char_accuracies'].items(),
        key=lambda x: x[1],
        reverse=True
    )

    for char, acc in sorted_chars:
        if char not in ['<pad>', '<eos>']:
            print(f"'{char}': {acc:.2f}%")

if __name__ == "__main__":
    main()

"""
1.	What impact does using different learning rates have on model training? (ASK Claude)
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from copy import deepcopy
import time

def prepare_subset_data(df_train, subset_ratio=0.5):
    """準備子集數據"""
    # 隨機抽樣50%的數據
    subset_size = int(len(df_train) * subset_ratio)
    subset_indices = np.random.choice(len(df_train), subset_size, replace=False)
    return df_train.iloc[subset_indices].reset_index(drop=True)

def train_with_lr(model, train_loader, learning_rate, num_epochs=5, device='cuda'):
    """使用指定學習率訓練模型"""
    model_copy = deepcopy(model)
    model_copy.to(device)
    criterion = nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])
    optimizer = optim.Adam(model_copy.parameters(), lr=learning_rate)

    history = {
        'loss': [],
        'epoch_times': []
    }

    for epoch in range(num_epochs):
        model_copy.train()
        epoch_loss = 0
        batch_count = 0
        epoch_start = time.time()

        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(device), y.to(device)

            optimizer.zero_grad()
            output = model_copy(x)

            loss = criterion(
                output[:, :-1].reshape(-1, output.size(-1)),
                y[:, 1:].reshape(-1)
            )

            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()
            batch_count += 1

            # 每50個batch輸出一次損失
            if batch_count % 1000 == 0:
                avg_loss = epoch_loss / batch_count
                history['loss'].append(avg_loss)
                print(f"LR {learning_rate}: Epoch {epoch+1}, Batch {batch_count}, Loss: {avg_loss:.4f}")

        epoch_time = time.time() - epoch_start
        history['epoch_times'].append(epoch_time)

        print(f"\nLR {learning_rate}: Epoch {epoch+1} 完成, "
              f"平均損失: {epoch_loss/batch_count:.4f}, "
              f"耗時: {epoch_time:.2f}秒")

    return history

def analyze_learning_rates():
    """分析不同學習率的效果"""
    # 設定要測試的學習率
    learning_rates = [0.0001, 0.001, 0.01]
    histories = {}
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 準備50%的訓練數據
    subset_df = prepare_subset_data(df_train, subset_ratio=0.5)
    print(f"使用數據集大小: {len(subset_df)} (原始數據集的50%)")

    # 初始化模型和數據加載器
    base_model = CharRNN(vocab_size=len(char_to_id), embed_dim=64, hidden_dim=128)
    train_loader = torch.utils.data.DataLoader(
        Dataset(subset_df),
        batch_size=32,  # 稍微增加batch_size以加快訓練
        shuffle=True,
        collate_fn=collate_fn
    )

    # 使用不同學習率訓練
    for lr in learning_rates:
        print(f"\n開始訓練 - 學習率: {lr}")
        histories[lr] = train_with_lr(base_model, train_loader, lr, num_epochs=5, device=device)

    # 繪製損失曲線
    plt.figure(figsize=(12, 6))
    for lr, history in histories.items():
        plt.plot(history['loss'], label=f'學習率 = {lr}')

    plt.xlabel('訓練批次 (x50)')
    plt.ylabel('損失')
    plt.title('不同學習率的訓練損失曲線比較')
    plt.legend()
    plt.grid(True)
    plt.yscale('log')
    plt.show()

    # 比較訓練時間
    plt.figure(figsize=(10, 5))
    avg_epoch_times = [np.mean(history['epoch_times']) for history in histories.values()]
    plt.bar([str(lr) for lr in learning_rates], avg_epoch_times)
    plt.xlabel('學習率')
    plt.ylabel('平均每輪訓練時間（秒）')
    plt.title('不同學習率的訓練時間比較')
    plt.show()

    # 計算和顯示結果
    print("\n學習率分析結果:")
    print("\n學習率    最終損失    平均每輪時間    損失波動性")
    print("-" * 55)
    for lr, history in histories.items():
        final_loss = history['loss'][-1]
        avg_time = np.mean(history['epoch_times'])
        loss_volatility = np.std(history['loss'])
        print(f"{lr:.4f}    {final_loss:.4f}        {avg_time:.2f}秒        {loss_volatility:.4f}")

    return histories

if __name__ == "__main__":
    results = analyze_learning_rates()

"""
2.If you use RNN or GRU instead of LSTM, what will happen to the quality of your answer generation? (ASK Claude)
"""

import torch
import torch.nn as nn
import numpy as np
import time
from copy import deepcopy

class BaseRNN(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, rnn_type='lstm'):
        super(BaseRNN, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=char_to_id['<pad>'])

        # 根據指定類型選擇RNN層
        if rnn_type == 'rnn':
            self.rnn1 = nn.RNN(embed_dim, hidden_dim, batch_first=True)
            self.rnn2 = nn.RNN(hidden_dim, hidden_dim, batch_first=True)
        elif rnn_type == 'gru':
            self.rnn1 = nn.GRU(embed_dim, hidden_dim, batch_first=True)
            self.rnn2 = nn.GRU(hidden_dim, hidden_dim, batch_first=True)
        else:  # lstm
            self.rnn1 = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
            self.rnn2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)

        self.linear = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, vocab_size)
        )

        self.rnn_type = rnn_type

    def forward(self, x):
        embedded = self.embedding(x)
        output1, _ = self.rnn1(embedded)
        output2, _ = self.rnn2(output1)
        return self.linear(output2)

def train_and_evaluate(model_type, train_loader, eval_loader, device, epochs=5):
    """訓練並評估指定類型的模型"""
    model = BaseRNN(
        vocab_size=len(char_to_id),
        embed_dim=64,
        hidden_dim=128,
        rnn_type=model_type
    ).to(device)

    criterion = nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    history = {
        'train_loss': [],
        'eval_loss': [],
        'eval_accuracy': [],
        'epoch_times': []
    }

    for epoch in range(epochs):
        # 訓練階段
        model.train()
        epoch_start = time.time()
        train_loss = 0
        batch_count = 0

        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()

            output = model(x)
            loss = criterion(
                output[:, :-1].reshape(-1, output.size(-1)),
                y[:, 1:].reshape(-1)
            )

            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            batch_count += 1

            if batch_count % 50 == 0:
                print(f"{model_type.upper()} - Epoch {epoch+1}, Batch {batch_count}, Loss: {loss.item():.4f}")

        avg_train_loss = train_loss / batch_count
        epoch_time = time.time() - epoch_start

        # 評估階段
        model.eval()
        eval_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for x, y in eval_loader:
                x, y = x.to(device), y.to(device)
                output = model(x)

                # 計算損失
                loss = criterion(
                    output[:, :-1].reshape(-1, output.size(-1)),
                    y[:, 1:].reshape(-1)
                )
                eval_loss += loss.item()

                # 計算準確率
                _, predicted = torch.max(output[:, :-1].reshape(-1, output.size(-1)), 1)
                targets = y[:, 1:].reshape(-1)
                mask = targets != char_to_id['<pad>']
                correct += (predicted[mask] == targets[mask]).sum().item()
                total += mask.sum().item()

        avg_eval_loss = eval_loss / len(eval_loader)
        accuracy = (correct / total * 100) if total > 0 else 0

        # 保存結果
        history['train_loss'].append(avg_train_loss)
        history['eval_loss'].append(avg_eval_loss)
        history['eval_accuracy'].append(accuracy)
        history['epoch_times'].append(epoch_time)

        print(f"\n{model_type.upper()} Epoch {epoch+1} 結果:")
        print(f"訓練損失: {avg_train_loss:.4f}")
        print(f"評估損失: {avg_eval_loss:.4f}")
        print(f"準確率: {accuracy:.2f}%")
        print(f"耗時: {epoch_time:.2f}秒\n")

    return history

def compare_models():
    """比較不同RNN模型的性能"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 準備數據
    subset_df = df_train.sample(frac=0.5, random_state=42)
    train_loader = torch.utils.data.DataLoader(
        Dataset(subset_df),
        batch_size=32,
        shuffle=True,
        collate_fn=collate_fn
    )

    eval_loader = torch.utils.data.DataLoader(
        Dataset(df_eval),
        batch_size=32,
        shuffle=False,
        collate_fn=collate_fn
    )

    # 訓練並評估每種模型
    model_types = ['rnn', 'gru', 'lstm']
    results = {}

    for model_type in model_types:
        print(f"\n開始訓練 {model_type.upper()} 模型...")
        results[model_type] = train_and_evaluate(
            model_type, train_loader, eval_loader, device
        )

    return results

if __name__ == "__main__":
    results = compare_models()

"""
3.  If construct an evaluation set using three-digit numbers while the training set is constructed from two-digit numbers,
    what will happen to the quality of your answer gener we ation? (ASK Claude)
"""
import pandas as pd
import random

def generate_balanced_three_digit_eval_data(num_samples=1000):
    """生成平衡的三位數測試數據"""
    data = []
    operations = ['+', '-', '*']

    # 確保每種運算符有相同數量的樣本
    samples_per_op = num_samples // len(operations)

    for op in operations:
        for _ in range(samples_per_op):
            # 生成三位數，確保分布均勻
            num1 = random.randint(100, 999)
            num2 = random.randint(100, 999)

            # 特殊處理減法，確保結果為正數
            if op == '-' and num1 < num2:
                num1, num2 = num2, num1

            # 計算結果
            if op == '+':
                result = num1 + num2
            elif op == '-':
                result = num1 - num2
            else:  # '*'
                result = num1 * num2

            # 構建原始算式並在末尾加上等號
            expr = f"{num1}{op}{num2}="

            data.append({
                'src': expr,
                'tgt': str(result),
            })

    # 轉換為 DataFrame
    df = pd.DataFrame(data)

    # 保存到 CSV 文件
    output_file = 'arithmetic_eval_3digit.csv'
    df.to_csv(output_file, index=False)
    print(f"\n數據已保存至: {output_file}")

    return df

if __name__ == "__main__":
    # 生成數據集
    print("正在生成三位數測試集...")
    df_eval_3digit = generate_balanced_three_digit_eval_data(num_samples=3000)  # 生成 3000 個樣本
    print("\n樣本示例:")
    print(df_eval_3digit.head())

def main():

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = CharRNN(vocab_size=len(char_to_id), embed_dim=64, hidden_dim=128)
    model.load_state_dict(torch.load('char_rnn_model_v3', map_location=device))
    model.to(device)
    model.eval()

    eval_dataset = Dataset(df_eval_3)
    eval_loader = torch.utils.data.DataLoader(
        eval_dataset,
        batch_size=16,
        shuffle=False,
        collate_fn=collate_fn
    )

    results = evaluate_model(model, eval_loader, device, char_to_id, id_to_char)

    print(f"\nEvaluation Results:")
    print(f"Overall Accuracy: {results['accuracy']:.2f}%")
    print(f"Average Loss: {results['loss']:.4f}")
    print("\nPer-character Accuracy:")

    sorted_chars = sorted(
        results['char_accuracies'].items(),
        key=lambda x: x[1],
        reverse=True
    )

    for char, acc in sorted_chars:
        if char not in ['<pad>', '<eos>']:
            print(f"'{char}': {acc:.2f}%")

if __name__ == "__main__":
    df_eval_3 = pd.read_csv('arithmetic_eval_3digit.csv')
    df_eval_3['tgt'] = df_eval_3['tgt'].apply(lambda x: str(x))
    df_eval_3['src'] = df_eval_3['src'].add(df_eval_3['tgt'])
    df_eval_3['len'] = df_eval_3['src'].apply(lambda x: len(x))
    df_eval_3['char_id_list'] = df_eval_3['src'].apply(lambda x: char_id(x, char_to_id))
    df_eval_3['label_id_list'] = df_eval_3['char_id_list'].apply(label_id, token_map=char_to_id)
    df_eval_3 = df_eval_3[['src', 'tgt', 'len', 'char_id_list', 'label_id_list']]
    print(df_eval_3.head())

    main()

"""
4.	If some numbers never appear in your training data,
    what will happen to your answer generation? (ASK Claude)
"""

import pandas as pd
import numpy as np

def filter_data_without_seven(df):
    # 檢查 src 欄位是否包含數字 7
    mask = ~df['src'].str.contains('7')
    # 取出不含 7 的資料
    df_filtered = df[mask].reset_index(drop=True)

    print(f"原始資料筆數: {len(df)}")
    print(f"篩選後資料筆數: {len(df_filtered)}")
    print(f"移除筆數: {len(df) - len(df_filtered)}")
    print(f"移除比例: {((len(df) - len(df_filtered)) / len(df) * 100):.2f}%")

    return df_filtered

# 篩選資料
df_train_no_seven = filter_data_without_seven(df_train)

# 顯示一些範例
print("\n篩選後資料範例:")
print(df_train_no_seven.head())

# 儲存篩選後的資料（可選）
df_train_no_seven.to_csv('arithmetic_train_no_seven.csv', index=False)

"""
5.	Why do we need gradient clipping during training? (ASK Claude)
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from copy import deepcopy
import time
import os
import pandas as pd
import re
from torch.nn.utils.rnn import pad_sequence

df_train = pd.read_csv('arithmetic_train.csv')
df_eval = pd.read_csv('arithmetic_eval.csv')
df_train.head()

# Transform the output data to string
df_train['tgt'] = df_train['tgt'].apply(lambda x: str(x))
df_train['src'] = df_train['src'].add(df_train['tgt'])
df_train['len'] = df_train['src'].apply(lambda x: len(x))

df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))
df_eval['src'] = df_eval['src'].add(df_eval['tgt'])
df_eval['len'] = df_eval['src'].apply(lambda x: len(x))

char_to_id = {}
id_to_char = {}

characters = ['<pad>', '<eos>', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-', '*', '(', ')', '=']
for idx, char in enumerate(characters):
    char_to_id[char] = idx
    id_to_char[idx] = char

vocab_size = len(char_to_id)

print('vocab_size: {}'.format(vocab_size))

def char_id(expr, token_map):
    tokens = re.findall(r'\d|[+\-*/=()]', expr)
    id_list = [token_map[token] for token in tokens if token in token_map]
    id_list.append(token_map['<eos>'])
    return id_list

def label_id(char_id_list, token_map):
    equal_pos = char_id_list.index(token_map['='])
    return [0] * (equal_pos+1) + char_id_list[equal_pos + 1:]

df_train['char_id_list'] = df_train['src'].apply(lambda x: char_id(x, char_to_id))
df_train['label_id_list'] = df_train['char_id_list'].apply(label_id, token_map=char_to_id)  # 等號後的
df_train = df_train[['src', 'tgt', 'len', 'char_id_list', 'label_id_list']]

df_eval['char_id_list'] = df_eval['src'].apply(lambda x: char_id(x, char_to_id))
df_eval['label_id_list'] = df_eval['char_id_list'].apply(label_id, token_map=char_to_id)
df_eval = df_eval[['src', 'tgt', 'len', 'char_id_list', 'label_id_list']]

df_train.head()

class Dataset(torch.utils.data.Dataset):
    def __init__(self, sequences):
        self.sequences = sequences

    def __len__(self):
        # return how much data is here in the Dataset object
        return len(self.sequences)

    def __getitem__(self, index):
        # Extract the input data x and the ground truth y from the data
        data = self.sequences.iloc[index]
        x = torch.tensor(data['char_id_list'])
        y = torch.tensor(data['label_id_list'])
        return x, y
class CharRNN(torch.nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim):
        super(CharRNN, self).__init__()  # 修正：加上括號

        # Embedding layer
        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,
                                          embedding_dim=embed_dim,
                                          padding_idx=char_to_id['<pad>'])

        # Two LSTM layers
        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim,
                                       hidden_size=hidden_dim,
                                       batch_first=True)

        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim,
                                       hidden_size=hidden_dim,
                                       batch_first=True)

        # Sequential layer with linear transformations and ReLU
        self.linear = torch.nn.Sequential(
            torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim),
            torch.nn.ReLU(),
            torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size)
        )

    def forward(self, x, target=None):
        # x shape: (batch_size, sequence_length)
        batch_size = x.size(0)
        sequence_length = x.size(1)

        # 1. 嵌入層處理所有輸入
        embedded = self.embedding(x)
        # embedded shape: (batch_size, sequence_length, embed_dim)

        # 2. 通過 LSTM 層
        output1, _ = self.rnn_layer1(embedded)
        output2, _ = self.rnn_layer2(output1)
        # output2 shape: (batch_size, sequence_length, hidden_dim)

        # 3. 通過線性層得到預測
        outputs = self.linear(output2)
        # outputs shape: (batch_size, sequence_length, vocab_size)

        return outputs

    def generator(self, start_char, max_len=200):
        # Convert input characters to IDs
        char_list = [char_to_id[c] for c in start_char]

        next_char = None

        while len(char_list) < max_len:
            # Pack the char_list to tensor
            x = torch.tensor(char_list).unsqueeze(0).to(next(self.parameters()).device)

            # Input the tensor through the model layers
            embedded = self.embedding(x)
            output1, _ = self.rnn_layer1(embedded)
            output2, _ = self.rnn_layer2(output1)
            y = self.linear(output2)

            # Obtain the next token prediction
            y = y[:, -1, :]  # Get the last prediction

            # Use argmax function to get the next token prediction
            next_char = torch.argmax(y, dim=-1).item()

            if next_char == char_to_id['<eos>']:
                break

            char_list.append(next_char)

        # Convert IDs back to characters
        return [id_to_char[ch_id] for ch_id in char_list]

# (ASK Claude and ChatGPT)
def collate_fn(batch):
    # 把序列和標籤分開
    sequences, labels = zip(*batch)

    # 使用 pad_sequence 自動處理填充
    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=char_to_id['<pad>'])
    padded_labels = pad_sequence(labels, batch_first=True, padding_value=char_to_id['<pad>'])

    return padded_sequences, padded_labels

def train_step(model, optimizer, criterion, x, y):
    # 1. 獲取模型預測
    logits = model(x)

    # 2. 計算損失（注意：y需要錯一位，因為我們在預測下一個字符）
    loss = criterion(
        logits[:, :-1].reshape(-1, logits.size(-1)),  # 除去最後一個預測
        y[:, 1:].reshape(-1)  # 除去第一個目標
    )

    # 3. 反向傳播和優化
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    return loss.item()

def train_with_clipping(model, train_loader, clip_value, num_epochs=5):
    """使用梯度裁剪的訓練函數"""
    device = next(model.parameters()).device
    model_copy = deepcopy(model)
    optimizer = torch.optim.Adam(model_copy.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])

    history = {
        'loss': [],
        'gradients': [],
        'clipped_gradients': []
    }

    for epoch in range(num_epochs):
        model_copy.train()
        epoch_loss = 0
        batch_count = 0

        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()

            # 前向傳播
            output = model_copy(x)
            loss = criterion(
                output[:, :-1].reshape(-1, output.size(-1)),
                y[:, 1:].reshape(-1)
            )

            # 反向傳播
            loss.backward()

            # 記錄原始梯度
            original_grad_norm = torch.nn.utils.clip_grad_norm_(
                model_copy.parameters(), float('inf')
            )
            history['gradients'].append(original_grad_norm.item())

            # 應用梯度裁剪
            clipped_grad_norm = torch.nn.utils.clip_grad_norm_(
                model_copy.parameters(), clip_value
            )
            history['clipped_gradients'].append(clipped_grad_norm.item())

            optimizer.step()

            epoch_loss += loss.item()
            batch_count += 1

            if batch_count % 50 == 0:
                avg_loss = epoch_loss / batch_count
                history['loss'].append(avg_loss)
                print(f"Epoch {epoch+1}, Batch {batch_count}, "
                      f"Loss: {avg_loss:.4f}, "
                      f"Gradient Norm: {original_grad_norm:.4f}, "
                      f"Clipped Norm: {clipped_grad_norm:.4f}")

    return history

def analyze_gradient_clipping():
    """分析不同梯度裁剪閾值的效果並保存圖表"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用設備: {device}")

    # 創建保存圖表的目錄
    os.makedirs('gradient_analysis', exist_ok=True)

    # 準備數據
    print("準備數據加載器...")
    train_loader = torch.utils.data.DataLoader(
        Dataset(df_train),
        batch_size=32,
        shuffle=True,
        collate_fn=collate_fn
    )

    # 測試不同的裁剪閾值
    clip_values = [1.0, 5.0, 10.0]
    results = {}

    # 初始化模型
    print("初始化模型...")
    base_model = CharRNN(vocab_size=len(char_to_id), embed_dim=64, hidden_dim=128)
    base_model.to(device)

    # 對每個裁剪閾值進行訓練
    for clip_value in clip_values:
        print(f"\n訓練模型 - 梯度裁剪閾值: {clip_value}")
        results[clip_value] = train_with_clipping(
            base_model, train_loader, clip_value
        )

    # 繪製並保存圖表
    print("\n生成分析圖表...")

    # 設置中文字體
    plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
    plt.rcParams['axes.unicode_minus'] = False

    # 創建圖表
    fig = plt.figure(figsize=(15, 10))

    # 1. 損失曲線
    plt.subplot(2, 2, 1)
    for clip_value, history in results.items():
        plt.plot(history['loss'], label=f'閾值={clip_value}')
    plt.xlabel('Batch (x50)')
    plt.ylabel('損失值')
    plt.title('不同梯度裁剪閾值的訓練損失')
    plt.legend()
    plt.grid(True)

    # 2. 梯度分布
    plt.subplot(2, 2, 2)
    for clip_value, history in results.items():
        plt.hist(history['gradients'],
                bins=50,
                alpha=0.5,
                label=f'閾值={clip_value}',
                density=True)
    plt.xlabel('梯度範數')
    plt.ylabel('密度')
    plt.title('梯度範數分布')
    plt.legend()
    plt.grid(True)

    # 3. 原始vs裁剪後梯度散點圖
    plt.subplot(2, 2, 3)
    for clip_value, history in results.items():
        plt.scatter(history['gradients'][:1000],
                   history['clipped_gradients'][:1000],
                   alpha=0.3,
                   label=f'閾值={clip_value}')
    plt.plot([0, max(max(h['gradients']) for h in results.values())],
             [0, max(max(h['clipped_gradients']) for h in results.values())],
             'k--', alpha=0.5)
    plt.xlabel('原始梯度範數')
    plt.ylabel('裁剪後梯度範數')
    plt.title('原始vs裁剪後梯度對比')
    plt.legend()
    plt.grid(True)

    # 4. 梯度裁剪效果時序圖
    plt.subplot(2, 2, 4)
    for clip_value, history in results.items():
        plt.plot(history['gradients'][:1000],
                label=f'原始 (閾值={clip_value})',
                alpha=0.5)
        plt.plot(history['clipped_gradients'][:1000],
                label=f'裁剪後 (閾值={clip_value})',
                alpha=0.5)
    plt.xlabel('訓練步驟')
    plt.ylabel('梯度範數')
    plt.title('梯度裁剪效果隨時間變化')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()

    # 保存圖表
    fig.savefig('gradient_analysis/gradient_clipping_analysis.png',
                dpi=300,
                bbox_inches='tight')
    plt.close()

    # 為每個閾值生成單獨的詳細分析圖
    for clip_value, history in results.items():
        fig, axs = plt.subplots(1, 2, figsize=(15, 5))

        # 損失曲線
        axs[0].plot(history['loss'])
        axs[0].set_xlabel('Batch (x50)')
        axs[0].set_ylabel('損失值')
        axs[0].set_title(f'閾值={clip_value}的訓練損失')
        axs[0].grid(True)

        # 梯度分布對比
        axs[1].hist(history['gradients'],
                   bins=50,
                   alpha=0.5,
                   label='原始梯度',
                   density=True)
        axs[1].hist(history['clipped_gradients'],
                   bins=50,
                   alpha=0.5,
                   label='裁剪後梯度',
                   density=True)
        axs[1].set_xlabel('梯度範數')
        axs[1].set_ylabel('密度')
        axs[1].set_title(f'閾值={clip_value}的梯度分布對比')
        axs[1].legend()
        axs[1].grid(True)

        plt.tight_layout()
        plt.savefig(f'gradient_analysis/clip_value_{clip_value}.png',
                   dpi=300,
                   bbox_inches='tight')
        plt.close()

    print(f"\n圖表已保存到 'gradient_analysis' 目錄")
    return results

if __name__ == "__main__":
    try:
        results = analyze_gradient_clipping()
        print("\n分析完成!")
    except Exception as e:
        print(f"執行時出現錯誤: {str(e)}")
        raise e